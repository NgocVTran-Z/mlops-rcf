name: Upload All Updated Scripts to S3 + Build SAM

on:
  push:
    paths:
      - '**.py'
      - '**.json'
      - 'template.yaml'

jobs:
  upload-and-build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Upload updated scripts to S3
        run: |
          echo "üì¶ Detecting changed Python/JSON files..."
          git fetch origin main
          CHANGED_FILES=$(git diff --name-only origin/main HEAD | grep -E '\.py$|\.json$' || true)
          
          for FILE in $CHANGED_FILES; do
            echo "üîÑ Uploading $FILE ..."
            
            if [[ "$FILE" == pipelines/* ]]; then
              # Read s3_script_path from corresponding config
              CONFIG_FILE=$(dirname "$FILE")/config.json
              if [[ -f "$CONFIG_FILE" ]]; then
                DEST=$(jq -r '.s3_script_path' "$CONFIG_FILE")
                aws s3 cp "$FILE" "$DEST"
              else
                echo "‚ö†Ô∏è No config.json for $FILE, skipping..."
              fi

            elif [[ "$FILE" == shared/* ]]; then
              # Upload shared module into shared/ in the script S3 path
              DEST=$(jq -r '.s3_script_path' pipelines/01_preprocessing_kmeans/config.json)
              SHARED_URI=$(dirname "$DEST")/shared/
              aws s3 cp "$FILE" "$SHARED_URI${FILE#shared/}"
            fi
          done

      - name: Install AWS SAM CLI
        uses: aws-actions/setup-sam@v2
        with:
          use-installer: false

      - name: SAM Build
        run: sam build

      - name: SAM Deploy (auto-confirm)
        run: |
          sam deploy --no-confirm-changeset --no-fail-on-empty-changeset --stack-name mlops-trigger-stack
